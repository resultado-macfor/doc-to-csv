import streamlit as st
import google.generativeai as genai
import pandas as pd
import os
from datetime import datetime
import tempfile
import io
import csv
import json
import re
from PIL import Image, ImageDraw, ImageFont
import fitz  # PyMuPDF
import pdf2image
from pdf2image import convert_from_bytes
import numpy as np

# Configura√ß√£o
st.set_page_config(page_title="Extrator de Cultivares", page_icon="üå±")
st.title("Extrator de Cultivares")

# API Key
gemini_api_key = os.getenv("GEMINI_API_KEY") or os.getenv("GEM_API_KEY")
if not gemini_api_key:
    st.error("Configure GEMINI_API_KEY")
    st.stop()

try:
    genai.configure(api_key=gemini_api_key)
    modelo_visao = genai.GenerativeModel("gemini-2.5-flash")
    modelo_texto = genai.GenerativeModel("gemini-2.5-flash")
except Exception as e:
    st.error(f"Erro ao configurar Gemini: {str(e)}")
    st.stop()

# Criar lista de meses detalhados
meses_detalhados = []
for mes in ["Janeiro", "Fevereiro", "Mar√ßo", "Abril", "Maio", "Junho", 
            "Julho", "Agosto", "Setembro", "Outubro", "Novembro", "Dezembro"]:
    for num in ["1", "2", "3"]:  # Janeiro 1, Janeiro 2, Janeiro 3, etc.
        meses_detalhados.append(f"{mes} {num}")

# COLUNAS EXATAS conforme o template
COLUNAS_EXATAS = [
    "Cultura", "Nome do produto", "NOME T√âCNICO/ REG", "Descritivo para SEO", 
    "Fertilidade", "Grupo de matura√ß√£o", "Lan√ßamento", "Slogan", "Tecnologia", 
    "Regi√£o (por extenso)", "Estado (por extenso)", "Ciclo", "Finalidade", 
    "URL da imagem do mapa", "N√∫mero do √≠cone 1", "Titulo icone 1", "Descri√ß√£o Icone 1", 
    "N√∫mero do √≠cone 2", "Titulo icone 2", "Descri√ß√£o Icone 2", "N√∫mero do √≠cone 3", 
    "Titulo icone 3", "Descri√ß√£o Icone 3", "N√∫mero do √≠cone 4", "T√≠tulo icone 4", 
    "Descri√ß√£o Icone 4", "N√∫mero do √≠cone 5", "T√≠tulo icone 5", "Descri√ß√£o Icone 5", 
    "Exig√™ncia √† fertilidade", "Grupo de maturidade", "PMS M√âDIO", "Tipo de crescimento", 
    "Cor da flor", "Cor da pubesc√™ncia", "Cor do hilo", "Cancro da haste", 
    "P√∫stula bacteriana ", "Nematoide das galhas - M. javanica", 
    "Nemat√≥ide de Cisto (Ra√ßa 3)", "Nemat√≥ide de Cisto (Ra√ßa 9)", 
    "Nemat√≥ide de Cisto (Ra√ßa 10)", "Nemat√≥ide de Cisto (Ra√ßa 14)", 
    "Fit√≥ftora (Ra√ßa 1)", "Recomenda√ß√µes", "Resultado 1 - Nome", "Resultado 1 - Local", 
    "Resultado 1", "Resultado 2 - Nome", "Resultado 2 - Local", "Resultado 2", 
    "Resultado 3 - Nome", "Resultado 3 - Local", "Resultado 3", "Resultado 4 - Nome", 
    "Resultado 4 - Local", "Resultado 4", "Resultado 5 - Nome", "Resultado 5 - Lcal", 
    "Resultado 5", "Resultado 6 - Nome", "Resultado 6 - Local", "Resultado 6", 
    "Resultado 7 - Nome", "Resultado 7 - Local", "Resultado 7", "REC", "UF", 
    "Regi√£o"
] + meses_detalhados  # Adicionar os 36 meses detalhados (12 meses √ó 3)

print(f"Total de colunas: {len(COLUNAS_EXATAS)}")
print(f"Meses detalhados: {meses_detalhados}")

# Session state
if 'df' not in st.session_state:
    st.session_state.df = pd.DataFrame(columns=COLUNAS_EXATAS)
if 'csv_content' not in st.session_state:
    st.session_state.csv_content = ""
if 'texto_transcrito' not in st.session_state:
    st.session_state.texto_transcrito = ""
if 'imagens_paginas' not in st.session_state:
    st.session_state.imagens_paginas = []
if 'pagina_atual' not in st.session_state:
    st.session_state.pagina_atual = 1

# Fun√ß√£o 1: Converter PDF para imagens (uma imagem por p√°gina)
def pdf_para_imagens(pdf_bytes):
    try:
        st.info("Convertendo PDF para imagens...")
        
        # Converter PDF para lista de imagens (uma por p√°gina)
        imagens = convert_from_bytes(
            pdf_bytes,
            dpi=300,  # DPI para boa qualidade de OCR
            fmt='PNG',
            thread_count=4,  # Usar m√∫ltiplas threads para processamento mais r√°pido
            poppler_path=None  # Se tiver poppler instalado, pode especificar o caminho
        )
        
        st.success(f"‚úÖ PDF convertido em {len(imagens)} p√°gina(s)")
        return imagens
        
    except Exception as e:
        st.error(f"Erro ao converter PDF para imagens: {str(e)}")
        st.info("Tentando m√©todo alternativo...")
        
        # M√©todo alternativo com PyMuPDF
        try:
            imagens = []
            
            # Abrir PDF com PyMuPDF
            doc = fitz.open(stream=pdf_bytes, filetype="pdf")
            
            for page_num in range(len(doc)):
                page = doc.load_page(page_num)
                
                # Definir matriz para renderiza√ß√£o em alta qualidade
                mat = fitz.Matrix(300/72, 300/72)  # 300 DPI
                
                # Renderizar p√°gina como imagem
                pix = page.get_pixmap(matrix=mat)
                
                # Converter para PIL Image
                img_data = pix.tobytes("ppm")
                img = Image.open(io.BytesIO(img_data))
                
                # Converter para RGB se necess√°rio
                if img.mode != 'RGB':
                    img = img.convert('RGB')
                
                imagens.append(img)
            
            doc.close()
            st.success(f"‚úÖ PDF convertido em {len(imagens)} p√°gina(s) - M√©todo alternativo")
            return imagens
            
        except Exception as e2:
            st.error(f"Erro no m√©todo alternativo: {str(e2)}")
            return []

# Fun√ß√£o 2: Processar imagens em lote para transcrever
def processar_imagens_em_lote(imagens, batch_size=10):
    """Processa imagens em lotes para evitar rate limits"""
    if not imagens:
        return ""
    
    texto_completo = ""
    total_paginas = len(imagens)
    
    # Criar barra de progresso
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for batch_start in range(0, total_paginas, batch_size):
        batch_end = min(batch_start + batch_size, total_paginas)
        batch_imagens = imagens[batch_start:batch_end]
        
        status_text.text(f"Processando p√°ginas {batch_start + 1} a {batch_end} de {total_paginas}...")
        
        for idx, imagem in enumerate(batch_imagens):
            pagina_num = batch_start + idx + 1
            progresso = pagina_num / total_paginas
            progress_bar.progress(progresso, text=f"Transcrevendo p√°gina {pagina_num}/{total_paginas}")
            
            try:
                # Converter imagem para bytes
                img_bytes = io.BytesIO()
                imagem.save(img_bytes, format='PNG', optimize=True)
                img_bytes = img_bytes.getvalue()
                
                # Prompt espec√≠fico para transcrever texto de cultivares
                prompt = """TRANSCREVA TODO o texto desta p√°gina EXATAMENTE como aparece.
                
                INSTRU√á√ïES IMPORTANTES:
                1. Transcreva TODO o texto vis√≠vel
                2. Mantenha a formata√ß√£o original (linhas, espa√ßos)
                3. Inclua tabelas, n√∫meros, datas
                4. Especial aten√ß√£o para:
                   - Nomes de cultivares (ex: Soja XYZ, Milho ABC)
                   - N√∫meros de registro (REC, Registro, RDC)
                   - Caracter√≠sticas t√©cnicas
                   - Regi√µes e estados
                   - Datas e per√≠odos
                   - Dados de produtividade
                5. Se houver texto em colunas, mantenha a ordem
                6. Se houver tabelas, transcreva linha por linha
                
                Retorne APENAS o texto transcrito."""
                
                response = modelo_visao.generate_content([
                    prompt,
                    {"mime_type": "image/png", "data": img_bytes}
                ])
                
                texto_pagina = response.text.strip()
                texto_completo += f"\n\n--- P√ÅGINA {pagina_num} ---\n{texto_pagina}\n"
                
                # Pequena pausa para evitar rate limit
                import time
                time.sleep(0.5)
                
            except Exception as e:
                texto_completo += f"\n\n--- ERRO P√ÅGINA {pagina_num}: {str(e)[:100]} ---\n"
                continue
        
        # Pequena pausa entre lotes
        import time
        if batch_end < total_paginas:
            time.sleep(2)
    
    progress_bar.empty()
    status_text.empty()
    
    return texto_completo

# Fun√ß√£o 3: Extrair dados do texto transcrito
def extrair_dados_para_csv(texto_transcrito):
    prompt = f"""
    ANALISE O TEXTO TRANSCRITO DE UM PDF SOBRE CULTIVARES AGR√çCOLAS:

    TEXTO TRANSCRITO:
    {texto_transcrito}

    SUA TAREFA: Extrair informa√ß√µes sobre cultivares e preencher estas {len(COLUNAS_EXATAS)} colunas:

    {', '.join(COLUNAS_EXATAS)}

    INSTRU√á√ïES DETALHADAS:

    1. IDENTIFICA√á√ÉO DE CULTIVARES:
       - Procure por nomes de cultivares (ex: "BRS 8380", "SYN 136", "DM 595")
       - Cada cultivar √∫nica deve ter uma linha no CSV
       - Se houver m√∫ltiplas cultivares no mesmo texto, crie uma entrada para cada

    2. FOCO NO CAMPO "REC" (CR√çTICO):
       - Procure por: "REC", que estar√° em uma tabelinha
       - Se uma cultivar tiver MAIS DE UM REC, crie uma LINHA SEPARADA para cada REC
       - Exemplo: Se cultivar "XYZ" tem REC 123 e REC 456, crie 2 linhas:
         Linha 1: Cultivar XYZ, REC 123, ...
         Linha 2: Cultivar XYZ, REC 456, ...

    3. PARA OS MESES (36 colunas detalhadas):
       - Formato: "Janeiro 1", "Janeiro 2", "Janeiro 3", "Fevereiro 1", ..., "Dezembro 3"
       - Preencha com "X" se for recomendado plantar nesse per√≠odo espec√≠fico
       - Deixe em branco ("") se n√£o for recomendado
       - Se a informa√ß√£o n√£o estiver dispon√≠vel, use "NR"

    4. PARA OUTROS CAMPOS IMPORTANTES:
       - "Cultura": Soja, Milho, Feij√£o, Trigo, etc.
       - "Nome do produto": Nome comercial
       - "Regi√£o (por extenso)": Sul, Sudeste, Centro-Oeste, Nordeste, Norte
       - "Estado (por extenso)": Rio Grande do Sul, S√£o Paulo, Mato Grosso, etc.
       - "Ciclo": Precoce, M√©dio, Tardio
       - "Lan√ßamento": Ano (ex: 2020, 2023)
       - "PMS M√âDIO": Peso de mil sementes (ex: "150-160 g")
       - Resist√™ncias: R (Resistente), MR (Moderadamente Resistente), S (Suscet√≠vel)
       - Produtividade: Mantenha formato "XX,XX sc/ha" ou "kg/ha"

    5. REGRAS GERAIS:
       - Use "NR" para informa√ß√µes n√£o encontradas
       - Mantenha os nomes das colunas EXATAMENTE como est√£o acima
       - Para campos num√©ricos, mantenha unidades quando aplic√°vel
       - Para m√∫ltiplos valores, separe com v√≠rgula
       - Para campos de texto, mantenha o texto original

    6. FORMATO DE SA√çDA:
       - Retorne APENAS um array JSON v√°lido
       - Cada objeto representa uma cultivar + REC (uma linha no CSV)
       - Cada objeto deve ter {len(COLUNAS_EXATAS)} propriedades
       - Nomes das propriedades DEVEM ser exatos
       - Inclua TODAS as propriedades, mesmo que vazias

    EXEMPLO DE SA√çDA PARA UMA CULTIVAR COM 2 RECs:
    [
      {{
        "Cultura": "Soja",
        "Nome do produto": "BRS 8380",
        "NOME T√âCNICO/ REG": "BRS 8380 IPRO",
        "REC": "12345",
        "Regi√£o (por extenso)": "Sul,Sudeste",
        "Estado (por extenso)": "Rio Grande do Sul,Paran√°,S√£o Paulo",
        "Ciclo": "M√©dio",
        "Lan√ßamento": "2020",
        "Janeiro 1": "X",
        "Janeiro 2": "X",
        "Janeiro 3": "",
        "Fevereiro 1": "X",
        "Fevereiro 2": "",
        "Fevereiro 3": "",
        ... // todas as outras 36 colunas de meses
        ... // todas as outras colunas
      }},
      {{
        "Cultura": "Soja",
        "Nome do produto": "BRS 8380",
        "NOME T√âCNICO/ REG": "BRS 8380 IPRO",
        "REC": "67890",
        "Regi√£o (por extenso)": "Centro-Oeste",
        "Estado (por extenso)": "Mato Grosso,Goi√°s",
        "Ciclo": "M√©dio",
        "Lan√ßamento": "2020",
        "Janeiro 1": "",
        "Janeiro 2": "",
        "Janeiro 3": "",
        "Fevereiro 1": "X",
        "Fevereiro 2": "X",
        "Fevereiro 3": "X",
        ... // todas as outras 36 colunas de meses
        ... // todas as outras colunas
      }}
    ]
    """
    
    try:
        # Dividir prompt se for muito longo
        max_chars = 30000
        if len(prompt) > max_chars:
            # Manter as instru√ß√µes completas e parte do texto
            texto_resumido = texto_transcrito[:max_chars - 20000]
            prompt = prompt.replace(texto_transcrito, f"{texto_resumido}\n...[texto continua al√©m do limite de caracteres]")
        
        response = modelo_texto.generate_content(prompt)
        resposta = response.text.strip()
        
        # Limpar resposta
        resposta_limpa = resposta.replace('```json', '').replace('```', '').replace('JSON', '').strip()
        
        # Tentar parsear JSON
        try:
            dados = json.loads(resposta_limpa)
            if isinstance(dados, list):
                st.info(f"‚úÖ Extra√≠dos {len(dados)} registro(s) (incluindo m√∫ltiplos RECs)")
                return dados
            elif isinstance(dados, dict):
                st.info(f"‚úÖ Extra√≠do 1 registro")
                return [dados]
            else:
                st.warning(f"Formato inesperado: {type(dados)}")
                return []
                
        except json.JSONDecodeError as je:
            st.warning(f"JSONDecodeError: {str(je)}")
            
            # Tentar extrair JSON da resposta
            # Procurar por array JSON
            array_match = re.search(r'(\[\s*\{.*\}\s*\])', resposta_limpa, re.DOTALL)
            if array_match:
                try:
                    json_str = array_match.group(1)
                    # Limpar poss√≠veis problemas
                    json_str = re.sub(r',\s*}', '}', json_str)  # Remover v√≠rgulas antes de }
                    json_str = re.sub(r',\s*]', ']', json_str)  # Remover v√≠rgulas antes de ]
                    dados = json.loads(json_str)
                    st.info(f"‚úÖ Extra√≠dos {len(dados)} registro(s) ap√≥s limpeza")
                    return dados
                except Exception as e:
                    st.warning(f"Erro ao parsear array extra√≠do: {str(e)}")
            
            # Procurar por m√∫ltiplos objetos
            obj_pattern = r'\{\s*"[^"]*"\s*:[^}]*\}'
            obj_matches = re.findall(obj_pattern, resposta_limpa, re.DOTALL)
            
            if obj_matches:
                dados = []
                for obj_str in obj_matches:
                    try:
                        obj = json.loads(obj_str)
                        dados.append(obj)
                    except:
                        continue
                if dados:
                    st.info(f"‚úÖ Extra√≠dos {len(dados)} registro(s) de m√∫ltiplos objetos")
                    return dados
            
            # √öltima tentativa: usar eval com seguran√ßa
            try:
                # Verificar se parece JSON
                if resposta_limpa.startswith('[') and resposta_limpa.endswith(']'):
                    # Substituir aspas simples por duplas
                    corrigido = resposta_limpa.replace("'", '"')
                    # Corrigir v√≠rgulas finais
                    corrigido = re.sub(r',\s*}', '}', corrigido)
                    corrigido = re.sub(r',\s*]', ']', corrigido)
                    
                    dados = json.loads(corrigido)
                    if isinstance(dados, list):
                        st.info(f"‚úÖ Extra√≠dos {len(dados)} registro(s) ap√≥s corre√ß√£o")
                        return dados
            except:
                pass
            
            st.error(f"N√£o foi poss√≠vel extrair JSON da resposta")
            return []
            
    except Exception as e:
        st.error(f"Erro na extra√ß√£o: {str(e)}")
        return []

# Fun√ß√£o 4: Criar DataFrame com tratamento de m√∫ltiplos RECs
def criar_dataframe(dados):
    if not dados or not isinstance(dados, list):
        return pd.DataFrame(columns=COLUNAS_EXATAS)
    
    linhas = []
    for item in dados:
        if isinstance(item, dict):
            linha = {}
            for coluna in COLUNAS_EXATAS:
                # Procurar valor
                valor = "NR"
                
                # Buscar exatamente
                if coluna in item:
                    valor = item[coluna]
                else:
                    # Buscar por similaridade (case insensitive)
                    for chave in item.keys():
                        if coluna.lower() == chave.lower():
                            valor = item[chave]
                            break
                        elif coluna.lower() in chave.lower() or chave.lower() in coluna.lower():
                            valor = item[chave]
                            break
                
                # Processar valor
                if valor is None:
                    valor = "NR"
                elif isinstance(valor, (int, float)):
                    valor = str(valor)
                elif not isinstance(valor, str):
                    valor = str(valor)
                
                # Para campos de meses, manter "X", "" ou "NR"
                if coluna in meses_detalhados:
                    if valor.strip().upper() in ["X", "SIM", "YES", "V", "‚úì", "‚úî"]:
                        valor = "X"
                    elif valor.strip() == "":
                        valor = ""
                    elif valor.strip().upper() == "NR":
                        valor = "NR"
                
                linha[coluna] = valor.strip() if isinstance(valor, str) and valor.strip() != "" else valor
            
            # Verificar se tem REC
            rec_valor = linha.get("REC", "NR")
            
            # Adicionar apenas se tiver dados v√°lidos E um REC (ou pelo menos algum dado)
            valores_validos = [v for v in linha.values() if v != "NR" and v != ""]
            if valores_validos:
                linhas.append(linha)
    
    if linhas:
        df = pd.DataFrame(linhas)
        
        # Garantir todas as colunas
        for col in COLUNAS_EXATAS:
            if col not in df.columns:
                df[col] = "NR"
        
        # Para colunas de meses, substituir "NR" por "" (vazio)
        for mes_col in meses_detalhados:
            if mes_col in df.columns:
                df[mes_col] = df[mes_col].apply(lambda x: "" if x == "NR" else x)
        
        # Ordenar colunas
        df = df[COLUNAS_EXATAS]
        
        # Ordenar por Cultura e REC
        if 'Cultura' in df.columns and 'REC' in df.columns:
            df = df.sort_values(['Cultura', 'REC']).reset_index(drop=True)
        
        return df
    else:
        return pd.DataFrame(columns=COLUNAS_EXATAS)

# Fun√ß√£o 5: Gerar CSV
def gerar_csv_para_gsheets(df):
    if df.empty:
        return ""
    
    output = io.StringIO()
    writer = csv.writer(output, delimiter=',', quotechar='"', quoting=csv.QUOTE_MINIMAL)
    
    # Escrever cabe√ßalho
    writer.writerow(COLUNAS_EXATAS)
    
    # Escrever dados
    for _, row in df.iterrows():
        linha = []
        for col in COLUNAS_EXATAS:
            valor = row.get(col)
            if pd.isna(valor) or valor is None:
                valor = ""
            elif isinstance(valor, str):
                valor = valor.strip()
            else:
                valor = str(valor).strip()
            
            # Para colunas vazias, manter vazio
            if valor in ["nan", "None", "null", "NaN", "<NA>", "NaT", "NR"]:
                valor = ""
            
            linha.append(valor)
        writer.writerow(linha)
    
    return output.getvalue()

# Fun√ß√£o 6: Pr√©-visualizar p√°ginas
def mostrar_previa_paginas(imagens, max_preview=5):
    st.markdown("### üìÑ Pr√©-visualiza√ß√£o das P√°ginas")
    
    cols = st.columns(min(len(imagens[:max_preview]), 5))
    
    for idx, (col, img) in enumerate(zip(cols, imagens[:max_preview])):
        with col:
            # Redimensionar para pr√©-visualiza√ß√£o
            preview = img.copy()
            preview.thumbnail((200, 300))
            st.image(preview, caption=f"P√°gina {idx + 1}", use_column_width=True)
    
    if len(imagens) > max_preview:
        st.info(f"... e mais {len(imagens) - max_preview} p√°gina(s)")

# Fun√ß√£o 7: Verificar dados de RECs
def verificar_recs(df):
    if df.empty or 'REC' not in df.columns:
        return
    
    # Contar RECs √∫nicos
    recs_validos = df[df['REC'] != '']['REC'].unique()
    recs_validos = [str(r).strip() for r in recs_validos if str(r).strip() != '']
    
    if recs_validos:
        st.markdown("### üîç An√°lise de RECs:")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.metric("RECs √önicos Encontrados", len(recs_validos))
        
        with col2:
            # Verificar m√∫ltiplos RECs por cultivar
            if 'Nome do produto' in df.columns:
                produtos_multiplos = []
                for produto in df['Nome do produto'].unique():
                    recs_produto = df[df['Nome do produto'] == produto]['REC'].unique()
                    recs_validos_produto = [r for r in recs_produto if str(r).strip() not in ['', 'NR']]
                    if len(recs_validos_produto) > 1:
                        produtos_multiplos.append(produto)
                
                st.metric("Cultivares com M√∫ltiplos RECs", len(produtos_multiplos))
        
        # Mostrar alguns RECs
        with st.expander("Ver lista de RECs encontrados"):
            for i, rec in enumerate(recs_validos[:20]):  # Mostrar at√© 20
                st.write(f"‚Ä¢ {rec}")
            if len(recs_validos) > 20:
                st.info(f"... e mais {len(recs_validos) - 20} RECs")

# Interface principal
def main():
    st.markdown("### üì§ Carregue um arquivo PDF com informa√ß√µes de cultivares")
    st.markdown(f"**Total de colunas no template: {len(COLUNAS_EXATAS)}**")
    
    uploaded_file = st.file_uploader(
        "Selecione um arquivo PDF:",
        type=["pdf"],
        help="PDF t√©cnico sobre cultivares agr√≠colas"
    )
    
    if uploaded_file:
        st.success(f"‚úÖ Arquivo carregado: **{uploaded_file.name}** ({uploaded_file.size:,} bytes)")
        
        col1, col2 = st.columns(2)
        with col1:
            processar = st.button("üöÄ Processar PDF", type="primary", use_container_width=True)
        with col2:
            if st.button("üóëÔ∏è Limpar tudo", use_container_width=True):
                st.session_state.df = pd.DataFrame(columns=COLUNAS_EXATAS)
                st.session_state.csv_content = ""
                st.session_state.texto_transcrito = ""
                st.session_state.imagens_paginas = []
                st.rerun()
        
        if processar:
            # Limpar estado anterior
            st.session_state.df = pd.DataFrame(columns=COLUNAS_EXATAS)
            st.session_state.csv_content = ""
            st.session_state.texto_transcrito = ""
            st.session_state.imagens_paginas = []
            
            try:
                # PASSO 1: Converter PDF para imagens
                with st.spinner("üîÑ Convertendo PDF para imagens..."):
                    imagens = pdf_para_imagens(uploaded_file.getvalue())
                    if not imagens:
                        st.error("‚ùå Falha ao converter PDF para imagens")
                        return
                    
                    st.session_state.imagens_paginas = imagens
                    st.success(f"‚úÖ {len(imagens)} p√°gina(s) convertida(s) com sucesso")
                
                # Mostrar pr√©via das p√°ginas
                mostrar_previa_paginas(imagens)
                
                # PASSO 2: Transcrever imagens
                with st.spinner("ü§ñ Transcrevendo texto das p√°ginas..."):
                    texto_completo = processar_imagens_em_lote(imagens)
                    
                    if texto_completo:
                        st.session_state.texto_transcrito = texto_completo
                        st.success(f"‚úÖ Transcri√ß√£o conclu√≠da ({len(texto_completo):,} caracteres)")
                    else:
                        st.error("‚ùå Falha na transcri√ß√£o")
                        return
                
                # PASSO 3: Extrair dados
                with st.spinner("üìä Extraindo dados estruturados..."):
                    dados = extrair_dados_para_csv(texto_completo)
                    
                    if dados:
                        st.info(f"‚ÑπÔ∏è {len(dados)} registro(s) encontrado(s)")
                        
                        # Criar DataFrame
                        df = criar_dataframe(dados)
                        st.session_state.df = df
                        
                        if not df.empty:
                            # Gerar CSV
                            csv_content = gerar_csv_para_gsheets(df)
                            st.session_state.csv_content = csv_content
                            st.success(f"‚úÖ {len(df)} linha(s) extra√≠da(s) com sucesso!")
                            
                            # Verificar campos importantes
                            verificar_recs(df)
                            
                        else:
                            st.warning("‚ö†Ô∏è DataFrame vazio ap√≥s processamento")
                    else:
                        st.warning("‚ö†Ô∏è Nenhum dado estruturado encontrado no texto")
                
            except Exception as e:
                st.error(f"‚ùå Erro no processamento: {str(e)}")
        
        # Mostrar resultados se existirem
        df = st.session_state.df
        
        if not df.empty:
            st.markdown("---")
            st.markdown(f"### üìã Resultados: {len(df)} linha(s) encontrada(s)")
            
            # Estat√≠sticas
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Total de Linhas", len(df))
            with col2:
                campos_preenchidos = sum([1 for col in df.columns if df[col].nunique() > 1 and not df[col].isna().all()])
                st.metric("Campos Preenchidos", f"{campos_preenchidos}/{len(COLUNAS_EXATAS)}")
            with col3:
                if 'REC' in df.columns:
                    rec_validos = sum([1 for val in df['REC'] if str(val).strip() not in ['', 'NR']])
                    st.metric("RECs V√°lidos", rec_validos)
            with col4:
                if 'Cultura' in df.columns:
                    culturas = df['Cultura'].nunique()
                    st.metric("Tipos de Cultura", culturas)
            
            # Mostrar texto transcrito (resumido)
            with st.expander("üìù Ver texto transcrito (resumido)"):
                texto_resumido = st.session_state.texto_transcrito[:5000] + "..." if len(st.session_state.texto_transcrito) > 5000 else st.session_state.texto_transcrito
                st.text_area("Texto extra√≠do:", texto_resumido, height=300)
            
            # Mostrar amostra dos dados de meses
            with st.expander("üìÖ Ver amostra dos dados de meses"):
                if any(mes in df.columns for mes in meses_detalhados):
                    meses_cols = [col for col in meses_detalhados if col in df.columns]
                    if meses_cols:
                        meses_sample = df[['Cultura', 'Nome do produto', 'REC'] + meses_cols[:6]].head(5)
                        st.dataframe(meses_sample, use_container_width=True)
            
            # Mostrar DataFrame
            st.markdown("### üìä Dados Extra√≠dos")
            
            # Filtrar colunas para visualiza√ß√£o (excluir colunas vazias)
            colunas_nao_vazias = [col for col in COLUNAS_EXATAS if col in df.columns and not df[col].isna().all() and df[col].nunique() > 1]
            
            if len(colunas_nao_vazias) < len(COLUNAS_EXATAS):
                st.info(f"Mostrando {len(colunas_nao_vazias)} colunas com dados (de {len(COLUNAS_EXATAS)} total)")
            
            st.dataframe(df[colunas_nao_vazias] if colunas_nao_vazias else df, use_container_width=True)
            
            # Download
            st.markdown("---")
            st.markdown("### üì• Download dos Dados")
            
            nome_base = uploaded_file.name.split('.')[0]
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            
            if st.session_state.csv_content:
                col_dl1, col_dl2, col_dl3 = st.columns(3)
                
                with col_dl1:
                    st.download_button(
                        label="‚¨áÔ∏è Baixar CSV",
                        data=st.session_state.csv_content.encode('utf-8'),
                        file_name=f"cultivares_{nome_base}_{timestamp}.csv",
                        mime="text/csv",
                        type="primary",
                        use_container_width=True
                    )
                
                with col_dl2:
                    # JSON
                    json_data = df.to_json(orient='records', indent=2, force_ascii=False)
                    st.download_button(
                        label="‚¨áÔ∏è Baixar JSON",
                        data=json_data.encode('utf-8'),
                        file_name=f"cultivares_{nome_base}_{timestamp}.json",
                        mime="application/json",
                        use_container_width=True
                    )
                
                with col_dl3:
                    # Excel
                    excel_buffer = io.BytesIO()
                    with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                        df.to_excel(writer, index=False, sheet_name='Cultivares')
                    excel_buffer.seek(0)
                    
                    st.download_button(
                        label="‚¨áÔ∏è Baixar Excel",
                        data=excel_buffer.getvalue(),
                        file_name=f"cultivares_{nome_base}_{timestamp}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        use_container_width=True
                    )
        
        elif st.session_state.texto_transcrito:
            st.info("üìù Texto transcrito dispon√≠vel, mas nenhum dado estruturado foi extra√≠do.")
            
            with st.expander("Ver texto transcrito"):
                texto_resumido = st.session_state.texto_transcrito[:2000] + "..." if len(st.session_state.texto_transcrito) > 2000 else st.session_state.texto_transcrito
                st.text_area("Texto:", texto_resumido, height=300)
    
    else:
        st.info("üëÜ **Carregue um arquivo PDF acima para come√ßar**")
        
        # Exemplo de uso
        with st.expander("‚ÑπÔ∏è Como usar esta ferramenta"):
            st.markdown(f"""
            ### üìã Fluxo de Processamento:
            
            1. **Carregue um PDF** com informa√ß√µes de cultivares agr√≠colas
            2. **Convers√£o autom√°tica**: Cada p√°gina vira uma imagem
            3. **Transcri√ß√£o com IA**: Gemini Vision extrai texto das imagens
            4. **Extra√ß√£o estruturada**: IA identifica e organiza os dados em {len(COLUNAS_EXATAS)} colunas
            5. **Gera√ß√£o de CSV**: Dados formatados para planilha
            
            ### üîç Dados extra√≠dos:
            - **Nomes de cultivares** (BRS, SYN, DM, etc.)
            - **N√∫meros de REC/Registro** (cada REC em linha separada)
            - **36 per√≠odos de plantio** (Janeiro 1 a Dezembro 3)
            - **Caracter√≠sticas t√©cnicas** (ciclo, fertilidade, resist√™ncias)
            - **Regi√µes e estados** recomendados
            
            ### ‚ö†Ô∏è Observa√ß√µes:
            - Processamento pode levar alguns minutos para PDFs grandes
            - Imagens de melhor qualidade = melhor reconhecimento
            - Verifique sempre os dados extra√≠dos
            - Cada REC gera uma linha separada no CSV
            """)

if __name__ == "__main__":
    main()
